{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant annotations in hail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hail import *\n",
    "hc = HailContext(log=\"/topmed.log\")\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import vcf to vds and split any multi allelic sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vds = hc.import_vcf('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/freeze.5b.chr10.phased.pass.minDP0.remDuplicates.vcf.bgz',min_partitions = 500).split_multi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import wgsa annotations as a key table. This line does the following:\n",
    "    1: import full csv\n",
    "    2: make a _variant_ type field\n",
    "    3: key by the variant\n",
    "    4: remove unneeded fields\n",
    "    5: split the vep annotations into an array for each variant (there can be multiple annotations)\n",
    "    6: expand each variant row to 1 row per vep annotation for ease of filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kt = hc.import_table('freezes_2a_3a_4.snp_indel.annotated.general20170422.subset.gz.chr20.csv',delimiter='\\t').annotate(\"v = chr+':'+pos+':'+ref+':'+alt\").annotate('v = Variant(v)').key_by('v').drop(['pos','alt','chr','ref','wgsa_version']).annotate(\"VEP_ensembl_Consequence = VEP_ensembl_Consequence.split(',')\").explode('VEP_ensembl_Consequence')\n",
    "\n",
    "# kt = hc.import_table('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/freezes_2a_3a_4.snp_indel.annotated.general20170422.subset.gz.chr21',delimiter='\\t').annotate(\"rchr = chr.replace('chr','')\").annotate(\"v = rchr+':'+pos+':'+ref+':'+alt\").annotate('v = Variant(v)').key_by('v').drop(['pos','alt','chr','ref','rchr']).annotate(\"VEP_ensembl_Consequence = VEP_ensembl_Consequence.split(',')\").explode('VEP_ensembl_Consequence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated vds with key table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vds = vds.annotate_variants_table(kt, root='va.wgsa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gtex_pan = hc.import_table('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/gtex_pan_rpkm2_hg19.csv',delimiter=',').annotate(\"rchr = chr.replace('chr','')\").annotate(\"start_pad = toInt(transcript_start)-5000\").annotate(\"end_pad = toInt(transcript_end)+5000\").annotate(\"i = rchr+':'+start_pad+'-'+end_pad\" ).annotate('i = Interval(i)').key_by('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# islet_trans_file = 'gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/t2dreamdb_rnaseq_avgFPKM_greater2.bed'\n",
    "# islet_trans = hc.import_table(islet_trans_file,delimiter='\\t').annotate(\"start_pad = toInt(start_position)-5000\").annotate(\"end_pad = toInt(end_position)+5000\").annotate(\"i = chromosome_name+':'+start_pad+'-'+end_pad\" ).annotate('i = Interval(i)').key_by('i')\n",
    "islet_trans = KeyTable.import_bed(\"gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/t2dreamdb_rnaseq_avgFPKM_greater2.bed\")\n",
    "islet_trans_pad = KeyTable.import_bed(\"gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/t2dreamdb_rnaseq_avgFPKM_greater2_padding.bed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the islet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "islet_states = KeyTable.import_bed('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/Islets.chromatinStates.reformat.hg38.bed').filter('target == \"10_Active_enhancer_2\" || target == \"9_Active_enhancer_1\"')                           \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load islet tfbs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "islet_tfbs_file = 'gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/all_tfbs_chr10.tss.hg38.bed'\n",
    "islet_tfbs = KeyTable.import_bed(islet_tfbs_file)\n",
    "# islet_tfbs = hc.import_table(islet_tfbs_file,delimiter=',').annotate(\"i = V1+':'+V2+'-'+V3\" ).annotate('i = Interval(i)').key_by('i')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variants that fall within expressed genes or islet states or ptv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds_all_in_gene_pad = vds.filter_variants_table(islet_trans_pad).variant_qc().cache().filter_variants_expr('va.qc.AF < 0.01').annotate_variants_table(islet_trans_pad,root='va.gene').annotate_variants_table(islet_states,root='va.chr_state').annotate_variants_table(islet_tfbs,root='va.tfbs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds_all_in_gene = vds.filter_variants_table(islet_trans).variant_qc().cache().filter_variants_expr('va.qc.AF < 0.01').annotate_variants_table(islet_trans,root='va.gene').annotate_variants_table(islet_states,root='va.chr_state').annotate_variants_table(islet_tfbs,root='va.tfbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vds_ptv = vds_all_in_gene.filter_variants_expr('va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"splice_acceptor_variant\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"splice_donor_variant\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"splice_region_variant\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"stop_gained\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"stop_lost\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"start_gained\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"start_lost\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"frameshift_variant\"))')\n",
    "# vds_ptv = vds_all_in_gene_pad.filter_variants_expr('va.wgsa.VEP_ensembl_Consequence == \"splice_acceptor_variant\"  || va.wgsa.VEP_ensembl_Consequence == \"splice_donor_variant\" || va.wgsa.VEP_ensembl_Consequence== \"splice_region_variant\" || va.wgsa.VEP_ensembl_Consequence == \"stop_gained\" || va.wgsa.VEP_ensembl_Consequence == \"stop_lost\" || va.wgsa.VEP_ensembl_Consequence == \"start_gained\" || va.wgsa.VEP_ensembl_Consequence == \"start_lost\" || va.wgsa.VEP_ensembl_Consequence == \"frameshift_variant\"')\n",
    "vds_tfbs = vds_all_in_gene.filter_variants_table(islet_tfbs)\n",
    "vds_states = vds_all_in_gene.filter_variants_table(islet_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vds_subset = VariantDataset.union([vds_tfbs,vds_ptv])\n",
    "vds_tfbs.write('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/chr10_tfbs.vds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds_states.write('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/chr10_states.vds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vds_ptv.write('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/chr10_ptv.vds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Struct{rsid:String,qual:Double,filters:Set[String],info:Struct{AC:Array[Int],AN:Int},qc:Struct{callRate:Double,AC:Int,AF:Double,nCalled:Int,nNotCalled:Int,nHomRef:Int,nHet:Int,nHomVar:Int,dpMean:Double,dpStDev:Double,gqMean:Double,gqStDev:Double,nNonRef:Int,rHeterozygosity:Double,rHetHomVar:Double,rExpectedHetFrequency:Double,pHWE:Double},gene:String,chr_state:String,tfbs:String}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_vds = hc.read(['gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/chr10_tfbs.vds', 'gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/chr10_states.vds'])\n",
    "union_vds.variant_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "union_vds.export_variants('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/freeze5b_chr10_islet_states_tfbs.tsv', 'group_id = va.gene, chromosome = v.locus.contig, variant_id = va.rsid, position=v.locus.position, ref = v.ref, alt=v.alt, chromatin_state = va.chr_state, tfbs = va.tfbs, allele_count = va.qc.AC')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variant(contig=chr10, start=826806, ref=G, alts=[AltAllele(ref=G, alt=C)]),\n",
       " Variant(contig=chr10, start=826823, ref=A, alts=[AltAllele(ref=A, alt=G)]),\n",
       " Variant(contig=chr10, start=826825, ref=G, alts=[AltAllele(ref=G, alt=A)]),\n",
       " Variant(contig=chr10, start=826833, ref=T, alts=[AltAllele(ref=T, alt=C)]),\n",
       " Variant(contig=chr10, start=826854, ref=T, alts=[AltAllele(ref=T, alt=C)])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vds.query_variants('variants.take(5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# ! pip install firecloud\n",
    "# from firecloud import fiss\n",
    "# import pandas as pd\n",
    "# import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vds_subset = vds_subset.variant_qc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_model = fiss.fapi.get_entities_tsv(\"topmed-shared\",\"topmed-shared\", \"sample\")\n",
    "# data_model_text = pd.read_csv(io.StringIO(data_model.text), sep='\\t')[['entity:sample_id','participant','CENTER','study','topmed_project']]\n",
    "# data_model_text.rename(columns = {'entity:sample_id':'ent_sample_id', 'participant':'sample_id'}, inplace = True)\n",
    "# data_model_text[['study', 'topmed_project']] = data_model_text[['study', 'topmed_project']].astype(str)\n",
    "# from pyspark.sql import SQLContext\n",
    "# sqlctx = SQLContext(hc.sc)\n",
    "# spark_df = sqlctx.createDataFrame(data_model_text)\n",
    "# kt = KeyTable.from_dataframe(spark_df,key='sample_id')\n",
    "# vds = vds_subset.annotate_samples_table(kt, root='sa').sample_qc()\n",
    "# vds = vds.annotate_samples_expr('sa.nDoubles = gs.filter(g => g.isHet() && va.qc.AC == 2).count()')\n",
    "# vds = vds.annotate_samples_expr('sa.nTri_to_one = gs.filter(g => g.isHet() && va.qc.AC == 3).count()')\n",
    "# vds = vds.annotate_samples_expr('sa.nOne = gs.filter(g => g.isHet() && va.qc.AF < 0.01 && va.qc.AF > 0.001).count()')\n",
    "# vds = vds.annotate_samples_expr('sa.nTen = gs.filter(g => g.isHet() && va.qc.AF < 0.1 && va.qc.AF > 0.01).count()')\n",
    "# vds = vds.annotate_samples_expr('sa.nTen_above = gs.filter(g => g.isHet() && va.qc.AF > 0.1).count()')\n",
    "# vds.samples_table().aggregate_by_key(key_expr=['Pop = sa.topmed_project'], agg_expr=['Singletons = sa.map(s => sa.qc.nSingleton).stats().sum',\n",
    "#                                                                                           'Doubletons = sa.map(s => sa.nDoubles).stats().sum',\n",
    "#                                                                                           'Tripletons_to_01 = sa.map(sa => sa.nTri_to_one).stats().sum',\n",
    "#                                                                                           'Zero_1_to_1 = sa.map(sa => sa.nOne).stats().sum']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vds.samples_table().aggregate_by_key(key_expr=['Pop = sa.topmed_project'], agg_expr=['Single = sa.map(s => sa.qc.nSingleton).stats()']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}